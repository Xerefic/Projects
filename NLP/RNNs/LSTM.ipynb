{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3810jvsc74a57bd06dce376d6802de2db05f38814d622594779557761cf1ad656f198897303a7367",
   "display_name": "Python 3.8.10 64-bit ('torch': conda)"
  },
  "metadata": {
   "interpreter": {
    "hash": "6dce376d6802de2db05f38814d622594779557761cf1ad656f198897303a7367"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from dataloader import *\n",
    "from model import *\n",
    "from train import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = %pwd\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_df = pd.read_csv(os.path.join(PATH, 'train.csv'))\n",
    "print(main_df.shape)\n",
    "main_df = main_df.sample(n=main_df.shape[0])\n",
    "main_df = main_df[[\"question_text\", \"target\"]]\n",
    "main_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "o_class = main_df.loc[main_df.target == 0, :]\n",
    "l_class = main_df.loc[main_df.target == 1, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_o = o_class.iloc[:10000, :]\n",
    "test_l = l_class.iloc[:10000, :]\n",
    "\n",
    "valid_o = o_class.iloc[10000:20000, :]\n",
    "valid_l = l_class.iloc[10000:20000, :]\n",
    "\n",
    "train_o = o_class.iloc[20000:, :]\n",
    "train_l = l_class.iloc[20000:, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.concat([train_o, train_l], axis=0)\n",
    "print(train.shape)\n",
    "\n",
    "valid = pd.concat([valid_o, valid_l], axis=0)\n",
    "print(valid.shape)\n",
    "\n",
    "test = pd.concat([test_o, test_l], axis=0)\n",
    "print(test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.to_csv(os.path.join(PATH, \"inputs/train.csv\"), index=False)\n",
    "test.to_csv(os.path.join(PATH, \"inputs/test.csv\"), index=False)\n",
    "valid.to_csv(os.path.join(PATH, \"inputs/valid.csv\"), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del main_df, train, test, valid, train_l, train_o, test_l, test_o, valid_l,valid_o, o_class, l_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = CreateDataset(PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_iterator, valid_iterator, test_iterator = dataset.getData()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained_embeddings = dataset.getEmbeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = dataset.lengthVocab()[0]\n",
    "embedding_dim = 300\n",
    "hidden_dim = 374\n",
    "output_dim = 2\n",
    "num_layers = 2\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LSTM(input_dim, embedding_dim, hidden_dim, num_layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.embedding.weight.data = pretrained_embeddings.to(device)\n",
    "class_weights = torch.tensor([1.0, 15.0]).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(), lr=1e-4)\n",
    "criterion = nn.BCEWithLogitsLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to(device)\n",
    "criterion = criterion.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch_train_losses = []\n",
    "epoch_test_losses = []\n",
    "epoch_val_losses = []\n",
    "accu_train_epoch = []\n",
    "accu_test_epoch = []\n",
    "accu_val_epoch = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "def binary_accuracy(preds, y):\n",
    "\n",
    "    preds = torch.sigmoid(preds)\n",
    "    preds = torch.round(preds)\n",
    "\n",
    "    correct = (preds == y).float()\n",
    "    acc = correct.sum()/float(len(correct))\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyprind\n",
    "\n",
    "def train(model, iterator, optimizer, criterion):\n",
    "    \n",
    "    train_loss_batch = []\n",
    "    accu_train_batch = []\n",
    "    model.train()\n",
    "    bar = pyprind.ProgBar(len(iterator), bar_char='█')\n",
    "    for batch in iterator:\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "                \n",
    "        predictions = model.forward(batch.Text).view(-1)\n",
    "        batch.Label = (batch.Label).type_as(predictions)\n",
    "        train_loss = criterion(predictions, batch.Label)\n",
    "        acc = binary_accuracy(predictions, batch.Label)\n",
    "        \n",
    "        train_loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        train_loss_batch.append(train_loss)\n",
    "        accu_train_batch.append(acc)\n",
    "        bar.update()\n",
    "\n",
    "    epoch_train_losses.append(sum(train_loss_batch)/len(iterator))\n",
    "    accu_train_epoch.append(sum(accu_train_batch)/len(iterator))\n",
    "\n",
    "    return epoch_train_losses[-1], accu_train_epoch[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, iterator, criterion):\n",
    "    \n",
    "    val_loss_batch = []\n",
    "    accu_val_batch = []\n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        bar = pyprind.ProgBar(len(iterator), bar_char='█')\n",
    "        for batch in iterator:\n",
    "\n",
    "            predictions = model.forward(batch.Text).view(-1)\n",
    "            batch.Label = (batch.Label).type_as(predictions)\n",
    "            val_loss = criterion(predictions, batch.Label)\n",
    "            \n",
    "            acc = binary_accuracy(predictions, batch.Label)\n",
    "\n",
    "            val_loss_batch.append(val_loss)\n",
    "            accu_val_batch.append(acc)\n",
    "            bar.update()\n",
    "        epoch_val_losses.append(sum(val_loss_batch)/len(iterator))\n",
    "        accu_val_epoch.append(sum(accu_val_batch)/len(iterator))\n",
    "    return epoch_val_losses[-1], accu_val_epoch[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 2\n",
    "\n",
    "for epoch in range(epochs):\n",
    "\n",
    "    train_loss, train_acc = train(model, train_iterator, optimizer, criterion)\n",
    "    valid_loss, valid_acc = evaluate(model, valid_iterator, criterion)\n",
    "\n",
    "    print(f'| Epoch: {epoch+1:02} | Train Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}% | Val. Loss: {valid_loss:.3f} | Val. Acc: {valid_acc*100:.2f}% |')"
   ]
  }
 ]
}